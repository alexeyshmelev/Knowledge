{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEkTcg82y8UC"
      },
      "source": [
        "# Competition — Network Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yYSBpUTy8UE"
      },
      "source": [
        "### Challenge Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f31yjf3Ry8UE"
      },
      "source": [
        "Your goal is to generate a network that is as close as possible to the original real network. You do not have the original network in the explicit view, but you know some of its statistics. All statistics are in [`stats.txt`](https://drive.google.com/file/d/1xifvP4hVIHm6t6u2fdV6ZPNPC3euHMu1/view?usp=sharing) filethat contains a dictionary of the form\n",
        "* number_nodes (number of nodes): value\n",
        "* number_cc (number of connected components): value, sigma\n",
        "* radius (radius of giant component): value, sigma\n",
        "* diameter (diameter of giant component): value, sigma\n",
        "* average_clustering (average clustering coefficient): value, sigma\n",
        "* average_path_length (average path length): value, sigma\n",
        "* degree_cdf (empirical CDF of degree distribution): values, probabilities\n",
        "\n",
        "Meaning of all these sigmas is described in Evaluation section.\n",
        "\n",
        "You can use this code to draw CDF\n",
        "```python\n",
        "q_seq, p_seq = stats['degree_cdf']\n",
        "    plt.plot(\n",
        "        np.append(np.repeat(q_seq, 2)[1:], q_seq[-1]),\n",
        "        np.repeat(p_seq, 2)\n",
        "    )\n",
        "    plt.show()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28abaQbiy8UE"
      },
      "source": [
        "### Evaluation Criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBoLJofMy8UF"
      },
      "source": [
        "Your total score is calculated as weighted sum of 6 scores — similarities between statistics of original and generated networks. Each score takes values from the interval [0, 1], where 1 — absolute similarity with the original network. The scores are\n",
        "* \"KS\"\n",
        "    * 1 - KS_dist\n",
        "    * where KS_dist is Kolmogorov-Smirnov test statistic value\n",
        "* \"Radius\"\n",
        "    * $\\text{GK}(r, r', \\sigma_r) = \\exp\\left[-\\frac{(r - r')^2}{2\\sigma_r^2}\\right]$\n",
        "    * where GK is Gaussian Kernel, $r$ is a radius of the original network, $r'$ is a radius of a generated network, $\\sigma_r$ is a sigma of a radius from `stats.txt` file\n",
        "* \"Diameter\", \"Av. clustering\", \"Av. path length\", \"Number of CC\" are calculated by Gaussian Kernel in the same way\n",
        "* \"Total\"\n",
        "    * 1/6 KS + 1/6 Radius + 1/6 Diameter + 1/6 Av. clustering + 1/6 Av. path length + 1/6 Number of CC\n",
        "\n",
        "All scores immediately take value 0 if a generated network has incorrect number of nodes.\n",
        "\n",
        "**Baselines**\n",
        "\n",
        "Baselines 1-2 are calculated by the following algorithm:\n",
        "1. Generate a random degree sequence using Inverse Transform Sampling\n",
        "2. Generate a valid graph by Configuration Model\n",
        "3. Calculate total score\n",
        "4. Repeat 1-3 steps 1000 times and accumulate a set of total scores\n",
        "\n",
        "**Grades:**\n",
        "1. $total ≥ 0.1$\n",
        "2. $total ≥ 0.12$\n",
        "3. $total ≥ 0.15$\n",
        "4. $total ≥ 0.189$  (beat a mean total score)\n",
        "5.  $total ≥ 0.279$ (beat a mean + 3*sigma total score)\n",
        "6. $total ≥ 0.4$\n",
        "7. $total ≥ 0.486$\n",
        "8.  $total ≥ 0.6$\n",
        "9. $total ≥ 0.85$\n",
        "10. $total ≥ 0.95$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id2Ll2dOy8UF"
      },
      "source": [
        "### Submission Guidelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z9dDFP4y8UF"
      },
      "source": [
        "Submit a .ipynb file that generates the graph from scratch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown 1xifvP4hVIHm6t6u2fdV6ZPNPC3euHMu1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdAsbZjYoTD9",
        "outputId": "b15c6deb-698c-4b52-d9cf-56dc4805af60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xifvP4hVIHm6t6u2fdV6ZPNPC3euHMu1\n",
            "To: /content/stats.txt\n",
            "\r  0% 0.00/694 [00:00<?, ?B/s]\r100% 694/694 [00:00<00:00, 2.17MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat stats.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd723bX9olX7",
        "outputId": "d76d0f82-6407-4044-ca75-4a5f278a563f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"number_nodes\": 1882, \"radius\": [15, 2], \"diameter\": [28, 4], \"average_clustering\": [0.005066798238955518, 0.001], \"average_path_length\": [11.748410823170731, 2], \"number_cc\": [168, 32], \"degree_cdf\": [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 21, 24, 46], [0.0, 0.6902231668437833, 0.8517534537725824, 0.9086078639744952, 0.9378320935175345, 0.9516471838469713, 0.9654622741764081, 0.9723698193411264, 0.9776833156216791, 0.9808714133900106, 0.9845908607863975, 0.9888416578108395, 0.9893730074388948, 0.9925611052072264, 0.9936238044633369, 0.9952178533475027, 0.9957492029755579, 0.9968119022316685, 0.997874601487779, 0.9989373007438895, 0.9994686503719448, 1.0]]}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx"
      ],
      "metadata": {
        "id": "YKR3_vwz2YIJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # G = nx.erdos_renyi_graph(1882, 0.001, seed=42)\n",
        "\n",
        "# # G = nx.erdos_renyi_graph(34, 0.3, seed=42)\n",
        "# # G = nx.cycle_graph(34)\n",
        "# G = nx.path_graph(30)\n",
        "# # print(G.nodes)\n",
        "# for i in range(168):\n",
        "#     H = nx.path_graph(11)\n",
        "#     # H = nx.erdos_renyi_graph(11, 0.1, seed=42)\n",
        "#     # H = nx.cycle_graph(11)\n",
        "#     nx.relabel_nodes(H, {j:(30 + i*11 + j) for j in range(11)}, copy=False)\n",
        "#     G = nx.compose(G, H)\n",
        "\n",
        "# H = nx.path_graph(4)\n",
        "# nx.relabel_nodes(H, {j:(1878 + j) for j in range(4)}, copy=False)\n",
        "# G = nx.compose(G, H)\n",
        "\n",
        "\n",
        "# largest_cc = G.subgraph(max(nx.connected_components(G))).copy()"
      ],
      "metadata": {
        "id": "PeLZkWzro_tk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # G = nx.erdos_renyi_graph(1882, 0.001, seed=42)\n",
        "\n",
        "# # G = nx.erdos_renyi_graph(34, 0.3, seed=42)\n",
        "# # G = nx.cycle_graph(34)\n",
        "# G = nx.path_graph(30)\n",
        "# # print(G.nodes)\n",
        "# for i in range(166):\n",
        "#     H = nx.path_graph(11)\n",
        "#     nx.relabel_nodes(H, {j:(30 + i*11 + j) for j in range(11)}, copy=False)\n",
        "#     G = nx.compose(G, H)\n",
        "\n",
        "# for i in range(166, 168):\n",
        "#     H = nx.erdos_renyi_graph(11, 0.37, seed=42)\n",
        "#     nx.relabel_nodes(H, {j:(30 + i*11 + j) for j in range(11)}, copy=False)\n",
        "#     G = nx.compose(G, H)\n",
        "\n",
        "# H = nx.path_graph(4)\n",
        "# nx.relabel_nodes(H, {j:(1878 + j) for j in range(4)}, copy=False)\n",
        "# G = nx.compose(G, H)\n",
        "\n",
        "\n",
        "# largest_cc = G.subgraph(max(nx.connected_components(G))).copy()"
      ],
      "metadata": {
        "id": "WNZnxOMP3HQO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final answer is the cell below"
      ],
      "metadata": {
        "id": "4VDeLSCXL9z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.path_graph(34)\n",
        "G.add_edge(1, 8)\n",
        "\n",
        "for i in range(136):\n",
        "    H = nx.star_graph(10)\n",
        "    nx.relabel_nodes(H, {j:(34 + i*11 + j) for j in range(11)}, copy=False)\n",
        "    G = nx.compose(G, H)\n",
        "\n",
        "for i in range(136, 166):\n",
        "    H = nx.path_graph(11)\n",
        "    nx.relabel_nodes(H, {j:(34 + i*11 + j) for j in range(11)}, copy=False)\n",
        "    G = nx.compose(G, H)\n",
        "\n",
        "for i in range(166, 168):\n",
        "    H = nx.erdos_renyi_graph(11, 0.37, seed=42)\n",
        "    nx.relabel_nodes(H, {j:(34 + i*11 + j) for j in range(11)}, copy=False)\n",
        "    G = nx.compose(G, H)"
      ],
      "metadata": {
        "id": "qwWb-dBb9Il6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.write_edgelist(G, \"answer.edgelist\", data=False)"
      ],
      "metadata": {
        "id": "ER9DA5ufS2OO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some checks"
      ],
      "metadata": {
        "id": "5mA22Qt9M1jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "largest_cc = G.subgraph(max(nx.connected_components(G))).copy()\n",
        "print(f'Radius: {nx.radius(largest_cc)}, should be 15')\n",
        "print(f'Diameter: {nx.diameter(largest_cc)}, should be 28')\n",
        "print(f'Average path length: {nx.average_shortest_path_length(largest_cc)}, should be 11.7')\n",
        "\n",
        "print(f'Number of cc: {nx.number_connected_components(G)}')\n",
        "print(f'Number of nodes in cc: {nx.number_of_nodes(largest_cc)}')\n",
        "print(f'Number of nodes: {nx.number_of_nodes(G)}')\n",
        "print(f'Average clustering: {nx.average_clustering(G)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9-YWM70rPpF",
        "outputId": "de5a1e40-2e2e-4fdc-e10b-511e12ab03ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Radius: 15, should be 15\n",
            "Diameter: 29, should be 28\n",
            "Average path length: 10.807486631016042, should be 11.7\n",
            "Number of cc: 169\n",
            "Number of nodes in cc: 34\n",
            "Number of nodes: 1882\n",
            "Average clustering: 0.004893477050756542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "degree_seq = [d for n, d in G.degree]\n",
        "np.mean(degree_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6udd25NlHZB9",
        "outputId": "794646ad-8c7e-432d-d986-e0f23b32af50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.853347502656748"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(G, 'stats.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFqJKql2rE_d",
        "outputId": "f3cdd808-d7a1-4b4d-b956-9ea184c487e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ks_distance': 0.934643995749203,\n",
              " 'radius': 1.0,\n",
              " 'diameter': 0.9692332344763441,\n",
              " 'average_clustering': 0.9850921221682316,\n",
              " 'average_path_length': 0.8952365518174149,\n",
              " 'number_cc': 0.9995118379398894,\n",
              " 'total': 0.9639529570251804}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for evaluation"
      ],
      "metadata": {
        "id": "Cn4JfsBN9dQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code takes the graph G and path to the `stats.txt` file and computes all the scores.  "
      ],
      "metadata": {
        "id": "anBMBSRq-QC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BpdLHFV-y8UF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "from scipy.stats import ks_2samp\n",
        "\n",
        "def evaluate(G, stats_file='stats.txt'):\n",
        "    def gaussian_kde(l, r, sigma):\n",
        "      return np.exp(-(l - r)**2 / (2 * sigma**2))\n",
        "\n",
        "    def flatten(xss):\n",
        "      return [x for xs in xss for x in xs]\n",
        "\n",
        "    with open(stats_file, 'r') as file:\n",
        "        stats = eval(file.read())\n",
        "\n",
        "    #Incorrect number of nodes\n",
        "    if G.number_of_nodes() != stats['number_nodes']:\n",
        "        return {'kstest': 0,\n",
        "                'radius': 0,\n",
        "                'diameter': 0,\n",
        "                'average_clustering': 0,\n",
        "                'average_path_length': 0,\n",
        "                'number_cc': 0}\n",
        "    #Compute metrics\n",
        "    largest_cc = G.subgraph(max(nx.connected_components(G))).copy()\n",
        "    solution = {}\n",
        "    solution['radius'] = nx.radius(largest_cc)\n",
        "    solution['diameter'] = nx.diameter(largest_cc)\n",
        "    solution['average_clustering'] = nx.average_clustering(G)\n",
        "    solution['average_path_length'] = nx.average_shortest_path_length(largest_cc)\n",
        "    solution['number_cc'] = nx.number_connected_components(G)\n",
        "    degree_seq = [d for n, d in G.degree]\n",
        "\n",
        "    #Compare  scores\n",
        "    res = {}\n",
        "    stats['degree_seq'] = flatten([[deg] * count for deg, count in zip(stats['degree_cdf'][0][1:], np.round(np.diff(stats['degree_cdf'][1]) * stats['number_nodes']).astype('int'))] )\n",
        "    # print(np.unique(stats['degree_seq'], return_counts=True)) ####################################\n",
        "    # print(np.unique(degree_seq, return_counts=True)) ####################################\n",
        "    res['ks_distance'] = 1 - ks_2samp(degree_seq, stats['degree_seq']).statistic\n",
        "    for k in solution:\n",
        "        res[k] = gaussian_kde(solution[k], stats[k][0], stats[k][1])\n",
        "\n",
        "    #Compute final score\n",
        "    res['total'] = sum([res[k] for k in res]) / 6\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.path_graph(100)\n",
        "evaluate(G, 'stats.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjl5PNJB-weA",
        "outputId": "4df1452c-cd2e-40af-8ed5-665c6a51ee11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kstest': 0,\n",
              " 'radius': 0,\n",
              " 'diameter': 0,\n",
              " 'average_clustering': 0,\n",
              " 'average_path_length': 0,\n",
              " 'number_cc': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.path_graph(1882)\n",
        "evaluate(G, 'stats.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ08rBPv-9uP",
        "outputId": "3e7e3665-8b66-4912-a17f-cbec2300fcb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ks_distance': 0.3108395324123273,\n",
              " 'radius': 0.0,\n",
              " 'diameter': 0.0,\n",
              " 'average_clustering': 2.6625607850027013e-06,\n",
              " 'average_path_length': 0.0,\n",
              " 'number_cc': 1.2187610094869082e-06,\n",
              " 'total': 0.05180723562235364}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}